# Email Knowledge Base Agent with Conversation Logging

This project demonstrates an AI-powered agent built using Amazon Bedrock. The agent can answer questions based on the content of my personal email archive and also logs all user interactions and agent responses to an S3 bucket for auditing and analysis.

## Video Explanation




## Project Overview

During a 3-day hackathon, I developed a system that:
1.  Processes a Google Takeout MBOX file containing my emails.
2.  Filters and converts these emails into individual text files.
3.  Stores these processed emails in an Amazon S3 bucket.
4.  Uses these S3 files as a data source for an Amazon Bedrock Knowledge Base, powered by Amazon Kendra GenAI Index for intelligent retrieval.
5.  Provides a Streamlit-based web interface for users to ask questions.
6.  Employs an Amazon Bedrock Agent that utilizes the Knowledge Base to answer user queries.
7.  The Agent also includes a custom action (implemented via an AWS Lambda function) to log every user question and every agent response to a separate S3 bucket.
8.  Incorporates Amazon Bedrock Guardrails to ensure responsible AI behavior.

## Architecture & Components

The system comprises the following key components:

1.  **Data Source:** My personal email archive, initially exported from Gmail using Google Takeout as an `.mbox` file.
2.  **Email Processing Script (`mbox_converter_simplified_filter.py`):**
    *   **Purpose:** To convert the raw MBOX file into a collection of individual, clean text files suitable for ingestion into a Knowledge Base.
    *   **Functionality:**
        *   Parses the MBOX file.
        *   For each email, it extracts the plain text body.
        *   It prepends important metadata (Date, From, To, Subject) to the beginning of each email's content to provide context for the RAG system.
        *   It filters out emails based on a predefined list of keywords found in the sender's information (e.g., to exclude social media notifications, "no-reply" addresses).
        *   It also skips emails if no usable body content can be extracted.
        *   Saves each processed email as a separate `.txt` file with a unique filename (incorporating date, subject, and a unique ID).
3.  **Source S3 Bucket (`email-llm-s3-bucket`):**
    *   **Purpose:** To store the individual `.txt` email files generated by the Python script.
    *   This bucket serves as the direct data source for the Bedrock Knowledge Base.
4.  **Amazon Bedrock Knowledge Base:**
    *   **Name:** `email-llm-knowledge-base`
    *   **ID:** `BWXXMZEXGU`
    *   **Type:** Utilizes an Amazon Kendra GenAI Index for optimal retrieval accuracy and semantic understanding.
    *   **Data Source:** The `email-llm-s3-bucket`. Kendra ingests the `.txt` files, chunks them, and creates embeddings.
    *   **Embedding Model:** (Implicitly managed by Kendra when using Kendra GenAI Index, or a specified Bedrock embedding model like Titan Text Embeddings if a direct vector store was chosen for the KB).
5.  **Amazon Bedrock Agent (`trial-agent-email`):**
    *   **Purpose:** To orchestrate the interaction between the user, the Knowledge Base, and custom actions (like logging).
    *   **Foundation Model for Orchestration & Generation:** Anthropic Claude 3 Sonnet (e.g., `anthropic.claude-3-sonnet-20240229-v1:0`).
    *   **Key Configurations:**
        *   **Instructions:** Tells the agent its overall purpose, how to interact, when to use tools, and how to handle out-of-scope requests.
        *   **Knowledge Base Association:** Linked to the `email-llm-knowledge-base` to retrieve information from my emails.
        *   **Action Group for Logging:**
            *   **Name (example):** `ConversationLoggerGroup`
            *   **Lambda Function:** `AgentConversationLogger` (details below).
            *   **OpenAPI Schema:** Defines an endpoint (e.g., `/logTurn`) that the agent calls to trigger the logging Lambda.
        *   **Pre-processing Prompt Template (Optional but Recommended for Logging):** Could be used to trigger the logging of the user's question before orchestration.
        *   **Orchestration Prompt Template:** Modified to call the logging action group for user questions (if not done in pre-processing).
        *   **KB Response Generation Prompt Template:** Standard template to generate answers based on KB search results, including source citations.
        *   **Post-processing Prompt Template:** Modified to call the logging action group for the agent's final response before sending it to the user, and also to refine the agent's response for clarity.
6.  **AWS Lambda Function (`AgentConversationLogger`):**
    *   **Purpose:** To save text (either a user's question or an agent's response) to an S3 bucket.
    *   **Trigger:** Invoked by the Bedrock Agent via the `ConversationLoggerGroup` Action Group.
    *   **Input Parameters (from Agent):** `textToLog`, `conversationId`, `logType` ("user\_question" or "agent\_response").
    *   **Functionality:**
        *   Constructs a unique S3 key based on `LOGGING_S3_BASE_PREFIX / conversationId / logType_timestamp.txt`.
        *   Saves the `textToLog` as a `.txt` file to the `LOGGING_S3_BUCKET_NAME`.
        *   Returns a success status and the S3 path of the log file.
7.  **Logging S3 Bucket (`email-archive-foragent` or `[your-aws-account-id]-bedrock-agent-chatlogs`):**
    *   **Purpose:** To store the conversation logs (user questions and agent responses) generated by the `AgentConversationLogger` Lambda.
    *   **Organization:** Files are organized into folders based on `conversationId`, with each file named by `logType` and a unique timestamp.
8.  **Amazon Bedrock Guardrails:**
    *   **Purpose:** Implemented to ensure responsible AI behavior, filter harmful content, and prevent the agent from discussing off-limit topics.
    *   (I would add more details here about specific Guardrail configurations if I had them, e.g., "Blocked certain topics related to X, Y, Z" or "Filtered for harmful content categories P, Q, R").
9.  **Streamlit Web Interface (`app.py`):**
    *   **Purpose:** Provides a user-friendly chat interface to interact with the Bedrock Agent.
    *   **Functionality:**
        *   Takes user input.
        *   Calls the Bedrock Agent (likely using the `bedrock-agent-runtime` client's `invoke_agent` API).
        *   Displays the agent's response, including any citations from the Knowledge Base.

## How It Was Built (Key Steps)

1.  **Email Export:** I started by exporting my emails from Gmail using Google Takeout, which provided an `.mbox` file.
2.  **Email Processing:** I wrote a Python script (`mbox_converter_simplified_filter.py`) to:
    *   Read the `.mbox` file.
    *   Filter out unwanted emails (e.g., social media, no-reply addresses, or emails without a usable body).
    *   For each valid email, prepend metadata like `Date:`, `From:`, `To:`, `Subject:` to its plain text body.
    *   Save each processed email as an individual `.txt` file to a local folder.
3.  **S3 Setup for Source Emails:** I created an S3 bucket (`email-llm-s3-bucket`) and uploaded the processed `.txt` email files into it.
4.  **Knowledge Base Creation:**
    *   In Amazon Bedrock, I created a new Knowledge Base (`email-llm-knowledge-base`).
    *   I configured it to use the "Kendra GenAI Index" for best retrieval results.
    *   I added a data source pointing to the S3 bucket (`email-llm-s3-bucket`) containing my processed emails and initiated the first sync.
5.  **Logging Lambda Function (`AgentConversationLogger`):**
    *   I wrote the Python Lambda function to accept `textToLog`, `conversationId`, and `logType` as input.
    *   It saves the `textToLog` into a target S3 bucket (`email-archive-foragent` or similar), organizing files by `conversationId` and `logType_timestamp.txt`.
    *   I configured its IAM role with `s3:PutObject` permissions for the target logging bucket and basic Lambda execution permissions.
    *   I set environment variables in the Lambda for `LOGGING_S3_BUCKET_NAME` and `LOGGING_S3_BASE_PREFIX`.
6.  **Bedrock Agent Setup (`trial-agent-email`):**
    *   I created a new agent in Amazon Bedrock.
    *   **Instructions:** I provided general instructions on its role and how to behave.
    *   **Model:** I selected Anthropic Claude 3 Sonnet as the foundation model.
    *   **Knowledge Base Integration:** I associated the `email-llm-knowledge-base` with the agent.
    *   **Logging Action Group (`ConversationLoggerGroup`):**
        *   I created an Action Group, selecting "Define with API schemas."
        *   I selected the `AgentConversationLogger` Lambda function.
        *   I provided an OpenAPI schema defining an endpoint (e.g., `/logTurn`) with `POST` method, expecting `textToLog`, `conversationId`, and `logType` in the request body, and defining success/error responses.
    *   **Prompt Template Modifications:**
        *   **Orchestration:** I modified the orchestration prompt to instruct the agent to call the `logConversationTurn` action with `logType: "user_question"`, `$userInput$ as `textToLog`, and `$sessionId$` as `conversationId` at the beginning of its reasoning process for each user turn.
        *   **KB Response Generation:** I used or slightly adapted the default template, ensuring it uses `$search_results$` and outputs answers with source citations in the specified XML format. I also set a low temperature (e.g., 0.0-0.1) and added `</answer>` as a stop sequence.
        *   **Post-processing:** I modified the post-processing prompt to:
            1.  First, call the `logConversationTurn` action with `logType: "agent_response"`, `$agent_response$` (the raw output from orchestration/KB) as `textToLog`, and `$sessionId$` as `conversationId`.
            2.  Then, instruct the LLM to refine the `$agent_response$` into a user-friendly `<final_response>`, ensuring no internal function names are exposed.
            3.  I configured a slightly higher temperature (e.g., 0.3-0.5) for more natural rephrasing and added `</final_response>` as a stop sequence.
7.  **Guardrails Setup:** I configured Guardrails in Bedrock to define denied topics and filter for harmful content to ensure the agent responds responsibly.
8.  **Streamlit UI Development:**
    *   I created an `app.py` file using the Streamlit library.
    *   This app provides a chat interface.
    *   It uses `boto3` (Bedrock Agent Runtime client) to call the `invoke_agent` API with the user's input.
    *   It displays the agent's final response (which comes from the post-processing step) and any citations.
9.  **Testing and Iteration:**
    *   I tested the Knowledge Base directly.
    *   I tested the Lambda functions with sample events.
    *   I tested the full agent flow using the Bedrock Agent test console, carefully examining the **Trace** to debug orchestration, KB queries, action group invocations, and prompt template outputs.
    *   I iterated on the agent instructions and prompt templates to achieve the desired behavior.

## Why These Choices Were Made

*   **Bedrock Knowledge Base with Kendra GenAI Index:** Chosen for its superior semantic search and retrieval capabilities over large text datasets, which is ideal for an email archive to get the "best results."
*   **Bedrock Agent:** Provides the orchestration layer to combine the Knowledge Base with custom actions (like logging) and manage the conversation flow.
*   **Claude 3 Sonnet:** A powerful and capable LLM for both understanding user intent, orchestrating tasks, generating responses from KB context, and performing refinement in post-processing.
*   **Lambda for Custom Actions:** Standard serverless way to extend agent capabilities.
*   **S3 for Storage:** Scalable, durable, and cost-effective for storing both the processed emails and the conversation logs.
*   **Streamlit:** For rapid development of a user-friendly web interface for interacting with the agent.
*   **Explicit Logging Action:** Ensures a clear and auditable record of all interactions, which is important for understanding agent behavior, debugging, and potential future analysis or fine-tuning.
*   **Guardrails:** Essential for responsible AI deployment.

## How to Run the System

1.  **Prerequisites:**
    *   AWS Account with Bedrock, Kendra, S3, Lambda access configured.
    *   AWS CLI configured with appropriate credentials (or environment variables set for `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_SESSION_TOKEN`, `AWS_DEFAULT_REGION`).
    *   Python 3.9+ installed.
    *   Required Python libraries: `pip install streamlit boto3`.
2.  **Deploy AWS Resources:**
    *   Ensure the S3 buckets (source emails, logging target) exist.
    *   Deploy the `AgentConversationLogger` Lambda function with its code, environment variables, and IAM permissions.
    *   Ensure the Bedrock Knowledge Base (`email-llm-knowledge-base`) is created, linked to the source S3 bucket, and successfully synced.
    *   Ensure the Bedrock Agent (`trial-agent-email`) is created with:
        *   Correct instructions.
        *   Association with the Knowledge Base.
        *   The `ConversationLoggerGroup` Action Group correctly configured with its OpenAPI schema and linked to the `AgentConversationLogger` Lambda.
        *   Modified Orchestration and Post-processing prompt templates as described.
        *   Guardrails configured and attached.
3.  **Run the Email Processing Script (One-time or as needed for new emails):**
    ```bash
    python mbox_converter_simplified_filter.py "path/to/your/emails.mbox" "path/to/local_output_folder_for_txt_files"
    ```
    Then upload the contents of `path/to/local_output_folder_for_txt_files` to your source S3 bucket (`email-llm-s3-bucket`) and re-sync the Knowledge Base if necessary.
4.  **Run the Streamlit Application:**
    *   Update `app.py` with your correct `BEDROCK_REGION`, `AGENT_ID`, and `AGENT_ALIAS_ID`.
    *   Navigate to the directory containing `app.py`.
    *   Set AWS credentials as environment variables in your terminal.
    *   Run: `streamlit run app.py`
    *   Open the provided URL in your browser.

## Future Enhancements

*   More sophisticated error handling in the agent and Lambda functions.
*   Allowing the user to specify which emails (or types of emails) to archive via the agent.
*   User authentication for the Streamlit app.
*   Automated re-syncing of the Knowledge Base when new emails are processed.
*   More advanced parsing for email bodies (e.g., better HTML to text, handling of attachments).
